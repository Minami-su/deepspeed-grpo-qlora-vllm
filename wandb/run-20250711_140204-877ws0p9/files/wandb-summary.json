{"_step":35,"train/grad_norm":15.871825218200684,"profiling/Time taken: XGRPOTrainer._get_per_token_logps":0.23011406511068344,"train/completions/clipped_ratio":1,"train/completions/max_terminated_length":0,"profiling/Time taken: XGRPOTrainer.compute_loss":0.529917317442596,"train/rewards/accuracy_reward/std":0.10206206142902374,"train/completions/min_terminated_length":0,"train/epoch":0.021333333333333333,"train/reward_std":0.025515519082546234,"profiling/Time taken: XGRPOTrainer.accuracy_reward":0.3547811843454838,"train/rewards/format_reward/std":0,"profiling/Time taken: XGRPOTrainer._prepare_inputs":6.893649697303772e-06,"train/completions/mean_length":128,"profiling/Time taken: XGRPOTrainer.format_reward":0.0005397070199251175,"train/frac_reward_zero_std":0.9375,"_timestamp":1.7522137489010413e+09,"train/rewards/format_reward/mean":0,"_runtime":24.324581087,"train/num_tokens":25608,"train/clip_ratio/region_mean":0,"train/rewards/accuracy_reward/mean":0.010416666977107525,"train/kl":0,"train/completions/min_length":128,"train/reward":0.010416666977107525,"train/clip_ratio/high_mean":0,"profiling/Time taken: XGRPOTrainer.vLLM.generate":1.9410129683092237,"train/completions/mean_terminated_length":0,"train/clip_ratio/low_mean":0,"train/completions/max_length":128,"_wandb":{"runtime":25},"train/global_step":1,"train/loss":0,"train/clip_ratio/high_max":0,"train/learning_rate":0,"train/clip_ratio/low_min":0}