{"profiling/Time taken: XGRPOTrainer.vLLM.generate":1.743971161544323,"train/frac_reward_zero_std":1,"train/rewards/format_reward/mean":0,"train/learning_rate":0,"train/kl":0,"train/reward":0,"_wandb":{"runtime":29},"train/completions/clipped_ratio":1,"train/grad_norm":0,"profiling/Time taken: XGRPOTrainer.format_reward":0.0006366828456521034,"train/global_step":1,"train/completions/min_terminated_length":0,"_timestamp":1.7522172187900465e+09,"_step":35,"_runtime":28.392056746,"profiling/Time taken: XGRPOTrainer._prepare_inputs":8.814036846160889e-06,"train/completions/max_length":128,"train/reward_std":0,"train/rewards/format_reward/std":0,"train/num_tokens":25608,"train/clip_ratio/high_mean":0,"train/loss":0,"train/clip_ratio/region_mean":0,"train/clip_ratio/low_min":0,"profiling/Time taken: XGRPOTrainer.compute_loss":0.6270956825464964,"train/rewards/accuracy_reward/std":0,"train/rewards/accuracy_reward/mean":0,"train/completions/mean_length":128,"profiling/Time taken: XGRPOTrainer._get_per_token_logps":0.3271600417792797,"train/completions/mean_terminated_length":0,"train/epoch":0.021333333333333333,"profiling/Time taken: XGRPOTrainer.accuracy_reward":0.5453465534374118,"train/completions/min_length":128,"train/clip_ratio/high_max":0,"train/clip_ratio/low_mean":0,"train/completions/max_terminated_length":0}