{"profiling/Time taken: XGRPOTrainer._calculate_rewards":0.24879810772836208,"train/global_step":1,"profiling/Time taken: XGRPOTrainer._get_per_token_logps":0.25922101736068726,"train/completions/min_length":128,"_wandb":{"runtime":25},"train/reward_std":0,"profiling/Time taken: XGRPOTrainer.format_reward":0.0005808053538203239,"train/clip_ratio/region_mean":0,"profiling/Time taken: XGRPOTrainer.compute_loss":0.2705404544249177,"train/clip_ratio/low_mean":0,"train/clip_ratio/high_mean":0,"train/epoch":0.021333333333333333,"train/learning_rate":0,"profiling/Time taken: XGRPOTrainer._prepare_inputs":8.097849786281586e-06,"train/clip_ratio/low_min":0,"train/frac_reward_zero_std":1,"train/loss":0,"train/completions/mean_terminated_length":0,"train/num_tokens":25608,"train/completions/mean_length":128,"train/rewards/accuracy_reward/mean":0,"profiling/Time taken: XGRPOTrainer.vLLM.generate":2.103523659519851,"train/completions/min_terminated_length":0,"_step":28,"train/completions/clipped_ratio":1,"train/completions/max_terminated_length":0,"train/reward":0,"train/rewards/format_reward/std":0,"train/clip_ratio/high_max":0,"profiling/Time taken: XGRPOTrainer.accuracy_reward":0.24717930983752012,"train/completions/max_length":128,"train/rewards/accuracy_reward/std":0,"_timestamp":1.7522209993036242e+09,"train/grad_norm":0,"train/rewards/format_reward/mean":0,"_runtime":23.938565486}