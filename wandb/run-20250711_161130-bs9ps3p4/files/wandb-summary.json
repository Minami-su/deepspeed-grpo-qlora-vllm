{"_timestamp":1.7522215119864235e+09,"train/epoch":0.021333333333333333,"_runtime":21.441639812,"train/rewards/format_reward/std":0,"train/clip_ratio/low_min":0,"train/rewards/format_reward/mean":0,"train/frac_reward_zero_std":0.9375,"train/completions/max_terminated_length":0,"train/completions/min_length":128,"train/global_step":1,"train/learning_rate":0,"train/completions/mean_length":128,"train/rewards/accuracy_reward/mean":0.010416666977107525,"profiling/Time taken: XGRPOTrainer._prepare_inputs":5.71180135011673e-06,"train/loss":0,"train/completions/min_terminated_length":0,"profiling/Time taken: XGRPOTrainer._get_per_token_logps":0.2996942177414894,"profiling/Time taken: XGRPOTrainer.compute_loss":0.30179390776902437,"profiling/Time taken: XGRPOTrainer.format_reward":0.000554889440536499,"train/grad_norm":30.848562240600586,"_step":28,"train/completions/max_length":128,"train/completions/clipped_ratio":1,"profiling/Time taken: XGRPOTrainer.accuracy_reward":0.3553578769788146,"train/clip_ratio/region_mean":0,"profiling/Time taken: XGRPOTrainer._calculate_rewards":0.35694749746471643,"train/reward":0.010416666977107525,"train/num_tokens":25608,"train/completions/mean_terminated_length":0,"train/rewards/accuracy_reward/std":0.10206206142902374,"train/reward_std":0.025515517219901085,"train/clip_ratio/high_mean":0,"_wandb":{"runtime":22},"train/clip_ratio/low_mean":0,"train/clip_ratio/high_max":0,"profiling/Time taken: XGRPOTrainer.vLLM.generate":1.2412404529750347}