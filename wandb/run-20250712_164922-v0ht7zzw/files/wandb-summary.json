{"profiling/Time taken: SGRPOTrainer.vLLM.generate":1.4907840052619576,"train/completions/mean_length":128,"train/completions/min_terminated_length":0,"train/clip_ratio/high_mean":0,"train/epoch":0.12,"train/clip_ratio/low_min":0,"train/rewards/format_reward/mean":0,"train/rewards/accuracy_reward/mean":0,"train/completions/clipped_ratio":1,"train/num_tokens":389760,"profiling/Time taken: SGRPOTrainer._get_per_token_logps":0.4412275953218341,"train/loss":0,"train/global_step":15,"profiling/Time taken: SGRPOTrainer._calculate_rewards":0.04058925714343786,"train/reward":0,"_runtime":170.463505192,"train/completions/max_length":128,"train/frac_reward_zero_std":1,"profiling/Time taken: SGRPOTrainer.accuracy_reward":0.039342778734862804,"profiling/Time taken: SGRPOTrainer.compute_loss":0.44997591711580753,"train/grad_norm":0,"train/clip_ratio/high_max":0,"profiling/Time taken: SGRPOTrainer._move_lora_to_vllm":0.9524350464344025,"train/learning_rate":1.1052631578947369e-06,"train/clip_ratio/region_mean":0,"_step":455,"train/completions/max_terminated_length":0,"profiling/Time taken: SGRPOTrainer._prepare_inputs":2.671820502728224,"train/rewards/format_reward/std":0,"_timestamp":1.7523103327767997e+09,"train/completions/min_length":128,"train/completions/mean_terminated_length":0,"train/rewards/accuracy_reward/std":0,"profiling/Time taken: SGRPOTrainer.format_reward":0.0004260893911123276,"train/clip_ratio/low_mean":0,"_wandb":{"runtime":170},"train/reward_std":0}