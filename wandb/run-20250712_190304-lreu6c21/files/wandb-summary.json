{"profiling/Time taken: XGRPOTrainer._move_model_to_vllm":1.199818192049861,"train/completions/clipped_ratio":1,"train_loss":1.1651880558183336e-09,"_timestamp":1.7523217524268193e+09,"train_samples_per_second":0.63,"train/rewards/format_reward/mean":0,"train/completions/mean_length":128,"train/rewards/format_reward/std":0,"profiling/Time taken: XGRPOTrainer.format_reward":0.0004093041643500328,"train/clip_ratio/high_max":0,"_step":11250,"train/grad_norm":22.109661102294922,"train/learning_rate":6.517755456331153e-11,"train/loss":0,"train_steps_per_second":0.105,"train/rewards/accuracy_reward/std":0.20087526738643646,"_wandb":{"runtime":3570},"train/completions/min_terminated_length":0,"train/reward":0.0416666679084301,"train/completions/max_terminated_length":0,"profiling/Time taken: XGRPOTrainer.accuracy_reward":0.040857709012925625,"train/num_tokens":9.721967e+06,"train/completions/min_length":128,"train/clip_ratio/low_mean":0,"train/clip_ratio/high_mean":0,"profiling/Time taken: XGRPOTrainer._prepare_inputs":6.92903995513916e-06,"total_flos":0,"_runtime":3568.296633986,"profiling/Time taken: XGRPOTrainer.vLLM.generate":0.8050605226308107,"train_runtime":3571.2339,"profiling/Time taken: XGRPOTrainer.compute_loss":0.3839176706969738,"train/rewards/accuracy_reward/mean":0.0416666679084301,"profiling/Time taken: XGRPOTrainer._get_per_token_logps":0.3821232542395592,"train/clip_ratio/region_mean":0,"train/clip_ratio/low_min":0,"profiling/Time taken: XGRPOTrainer._calculate_rewards":0.04206646606326103,"train/completions/mean_terminated_length":0,"train/global_step":375,"train/frac_reward_zero_std":0.6666666865348816,"train/completions/max_length":128,"train/reward_std":0.10885214805603027,"train/epoch":3}