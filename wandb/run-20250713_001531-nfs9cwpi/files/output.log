  0%|          | 0/375 [00:00<?, ?it/s]
2025-07-13 00:15:41 - WARNING - latex2sympy2_extended.math_normalization - equations is deprecated, as it handled by the parser now
----------------------------------------------------------------------------------------------------

answer_parsed: [5, '5']
gold_parsed: [5, '5']
reward: 1.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [5, '5']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [5, '5']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [5, '5']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [5, '5']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [5, '5']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [5, '5']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [5, '5']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [5, '5']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [5, '5']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [5, '5']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [5, '5']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [5, '5']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [5, '5']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [5, '5']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [5, '5']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [{6, 8*,*10}, '6, 8\\text{, }10']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [{6, 8*,*10}, '6, 8\\text{, }10']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [{6, 8*,*10}, '6, 8\\text{, }10']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [{6, 8*,*10}, '6, 8\\text{, }10']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [{6, 8*,*10}, '6, 8\\text{, }10']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [{6, 8*,*10}, '6, 8\\text{, }10']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [{6, 8*,*10}, '6, 8\\text{, }10']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [{6, 8*,*10}, '6, 8\\text{, }10']
reward: 0.0
2025-07-13 00:15:41 - WARNING - latex2sympy2_extended.math_normalization - equations is deprecated, as it handled by the parser now
----------------------------------------------------------------------------------------------------

answer_parsed: ['<>,']
gold_parsed: [{6, 8*,*10}, '6, 8\\text{, }10']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [{6, 8*,*10}, '6, 8\\text{, }10']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [{6, 8*,*10}, '6, 8\\text{, }10']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [{6, 8*,*10}, '6, 8\\text{, }10']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [{6, 8*,*10}, '6, 8\\text{, }10']
reward: 0.0
2025-07-13 00:15:41 - WARNING - latex2sympy2_extended.math_normalization - equations is deprecated, as it handled by the parser now
----------------------------------------------------------------------------------------------------

answer_parsed: [(-1*3*k*m + 15)*byquotientdefinition/2, '\\frac{-3km+15}{2} \\text { (By Quotient Definition)}']
gold_parsed: [{6, 8*,*10}, '6, 8\\text{, }10']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [{6, 8*,*10}, '6, 8\\text{, }10']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [{6, 8*,*10}, '6, 8\\text{, }10']
reward: 0.0

accuracy rewards: [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
----------------------------------------------------------------------------------------------------

format rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
{'loss': 0.0, 'grad_norm': 90.29075622558594, 'learning_rate': 0.0, 'num_tokens': 25904.0, 'completions/mean_length': 128.0, 'completions/min_length': 128.0, 'completions/max_length': 128.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/accuracy_reward/mean': 0.02083333395421505, 'rewards/accuracy_reward/std': 0.14357589185237885, 'rewards/format_reward/mean': 0.0, 'rewards/format_reward/std': 0.0, 'reward': 0.02083333395421505, 'reward_std': 0.0833333358168602, 'frac_reward_zero_std': 0.6666666865348816, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01}
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [0, '0']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [0, '0']
reward: 0.0
2025-07-13 00:16:01 - WARNING - latex2sympy2_extended.math_normalization - equations is deprecated, as it handled by the parser now
----------------------------------------------------------------------------------------------------

answer_parsed: [12, '12']
gold_parsed: [0, '0']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [0, '0']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [0, '0']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [0, '0']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [0, '0']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [0, '0']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [0, '0']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [0, '0']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [0, '0']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [0, '0']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [0, '0']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [0, '0']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [0, '0']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [0, '0']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [4/3, '\\frac{4}{3}']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [4/3, '\\frac{4}{3}']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [4/3, '\\frac{4}{3}']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [4/3, '\\frac{4}{3}']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [4/3, '\\frac{4}{3}']
reward: 0.0
2025-07-13 00:16:01 - WARNING - latex2sympy2_extended.math_normalization - equations is deprecated, as it handled by the parser now
----------------------------------------------------------------------------------------------------

answer_parsed: [Eq(a, 0), 'a=0']
gold_parsed: [4/3, '\\frac{4}{3}']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [4/3, '\\frac{4}{3}']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [4/3, '\\frac{4}{3}']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [4/3, '\\frac{4}{3}']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [4/3, '\\frac{4}{3}']
reward: 0.0
2025-07-13 00:16:01 - WARNING - latex2sympy2_extended.math_normalization - equations is deprecated, as it handled by the parser now
----------------------------------------------------------------------------------------------------

answer_parsed: [-4/3, '\\frac{-4}{3}']
gold_parsed: [4/3, '\\frac{4}{3}']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [4/3, '\\frac{4}{3}']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [4/3, '\\frac{4}{3}']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [4/3, '\\frac{4}{3}']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [4/3, '\\frac{4}{3}']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [4/3, '\\frac{4}{3}']
reward: 0.0

accuracy rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
----------------------------------------------------------------------------------------------------

format rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
{'loss': 0.0, 'grad_norm': 78.32353973388672, 'learning_rate': 7.894736842105262e-08, 'num_tokens': 51552.0, 'completions/mean_length': 128.0, 'completions/min_length': 128.0, 'completions/max_length': 128.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/accuracy_reward/mean': 0.010416666977107525, 'rewards/accuracy_reward/std': 0.10206206142902374, 'rewards/format_reward/mean': 0.0, 'rewards/format_reward/std': 0.0, 'reward': 0.010416666977107525, 'reward_std': 0.0416666679084301, 'frac_reward_zero_std': 0.8333333730697632, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.02}
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [3, '3']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [3, '3']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [3, '3']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [3, '3']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [3, '3']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [3, '3']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [3, '3']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [3, '3']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [3, '3']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [3, '3']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [3, '3']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [3, '3']
reward: 0.0
2025-07-13 00:16:13 - WARNING - latex2sympy2_extended.math_normalization - equations is deprecated, as it handled by the parser now
----------------------------------------------------------------------------------------------------

answer_parsed: [Eq(g, 3/f(x)), 'g=3f^{-1}(x)']
gold_parsed: [3, '3']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [3, '3']
reward: 0.0
2025-07-13 00:16:13 - WARNING - latex2sympy2_extended.math_normalization - equations is deprecated, as it handled by the parser now
----------------------------------------------------------------------------------------------------

answer_parsed: [c*2, '\\text{(C) }2']
gold_parsed: [3, '3']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [3, '3']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [sqrt(5), '\\sqrt{5}']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [sqrt(5), '\\sqrt{5}']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [sqrt(5), '\\sqrt{5}']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [sqrt(5), '\\sqrt{5}']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [sqrt(5), '\\sqrt{5}']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [sqrt(5), '\\sqrt{5}']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [sqrt(5), '\\sqrt{5}']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [sqrt(5), '\\sqrt{5}']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [sqrt(5), '\\sqrt{5}']
reward: 0.0
2025-07-13 00:16:13 - WARNING - latex2sympy2_extended.math_normalization - equations is deprecated, as it handled by the parser now
----------------------------------------------------------------------------------------------------

answer_parsed: [1, '1']
gold_parsed: [sqrt(5), '\\sqrt{5}']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [sqrt(5), '\\sqrt{5}']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [sqrt(5), '\\sqrt{5}']
reward: 0.0
2025-07-13 00:16:13 - WARNING - latex2sympy2_extended.math_normalization - equations is deprecated, as it handled by the parser now
----------------------------------------------------------------------------------------------------

answer_parsed: [1, '1']
gold_parsed: [sqrt(5), '\\sqrt{5}']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [sqrt(5), '\\sqrt{5}']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [sqrt(5), '\\sqrt{5}']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [sqrt(5), '\\sqrt{5}']
reward: 0.0

accuracy rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
----------------------------------------------------------------------------------------------------

format rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.5789473684210525e-07, 'num_tokens': 76512.0, 'completions/mean_length': 128.0, 'completions/min_length': 128.0, 'completions/max_length': 128.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/accuracy_reward/mean': 0.0, 'rewards/accuracy_reward/std': 0.0, 'rewards/format_reward/mean': 0.0, 'rewards/format_reward/std': 0.0, 'reward': 0.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.02}
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [4, '4']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [4, '4']
reward: 0.0
2025-07-13 00:16:25 - WARNING - latex2sympy2_extended.math_normalization - equations is deprecated, as it handled by the parser now
----------------------------------------------------------------------------------------------------

answer_parsed: [2, '2']
gold_parsed: [4, '4']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [4, '4']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [4, '4']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [4, '4']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [4, '4']
reward: 0.0
2025-07-13 00:16:25 - WARNING - latex2sympy2_extended.math_normalization - equations is deprecated, as it handled by the parser now
----------------------------------------------------------------------------------------------------

answer_parsed: [128, '128']
gold_parsed: [4, '4']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [4, '4']
reward: 0.0
2025-07-13 00:16:25 - WARNING - latex2sympy2_extended.math_normalization - equations is deprecated, as it handled by the parser now
----------------------------------------------------------------------------------------------------

answer_parsed: [5/log(x, 10), '\\frac{5}{\\log_{10} x}']
gold_parsed: [4, '4']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [4, '4']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [4, '4']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [4, '4']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [4, '4']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [4, '4']
reward: 0.0
2025-07-13 00:16:25 - WARNING - latex2sympy2_extended.math_normalization - equations is deprecated, as it handled by the parser now
----------------------------------------------------------------------------------------------------

answer_parsed: [5*E*E*i*k*l*n*o*t*y, '5okieently']
gold_parsed: [4, '4']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [50000, '50000']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [50000, '50000']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [50000, '50000']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [50000, '50000']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [50000, '50000']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [50000, '50000']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [50000, '50000']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [50000, '50000']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [50000, '50000']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [50000, '50000']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [50000, '50000']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [50000, '50000']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [50000, '50000']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [50000, '50000']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [50000, '50000']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [50000, '50000']
reward: 0.0

accuracy rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
----------------------------------------------------------------------------------------------------

format rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 2.368421052631579e-07, 'num_tokens': 102192.0, 'completions/mean_length': 128.0, 'completions/min_length': 128.0, 'completions/max_length': 128.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/accuracy_reward/mean': 0.0, 'rewards/accuracy_reward/std': 0.0, 'rewards/format_reward/mean': 0.0, 'rewards/format_reward/std': 0.0, 'reward': 0.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03}
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [12, '12']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [12, '12']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [12, '12']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [12, '12']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [12, '12']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [12, '12']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [12, '12']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [12, '12']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [12, '12']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [12, '12']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [12, '12']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [12, '12']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [12, '12']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [12, '12']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [12, '12']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [12, '12']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [-3/2, '- \\frac{3}{2}']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [-3/2, '- \\frac{3}{2}']
reward: 0.0
2025-07-13 00:16:37 - WARNING - latex2sympy2_extended.math_normalization - equations is deprecated, as it handled by the parser now
2025-07-13 00:16:37 - WARNING - latex2sympy2_extended.math_normalization - equations is deprecated, as it handled by the parser now
----------------------------------------------------------------------------------------------------

answer_parsed: [{Eq(y, x - 2), Eq(y - 2, x)}, 'y-2 = x and y = x-2']
gold_parsed: [-3/2, '- \\frac{3}{2}']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [-3/2, '- \\frac{3}{2}']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [-3/2, '- \\frac{3}{2}']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [-3/2, '- \\frac{3}{2}']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [-3/2, '- \\frac{3}{2}']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [-3/2, '- \\frac{3}{2}']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [-3/2, '- \\frac{3}{2}']
reward: 0.0
2025-07-13 00:16:37 - WARNING - latex2sympy2_extended.math_normalization - equations is deprecated, as it handled by the parser now
----------------------------------------------------------------------------------------------------

answer_parsed: [3*f*r*a*c*(-3) + 2, '2 + 3frac{-1}{2}']
gold_parsed: [-3/2, '- \\frac{3}{2}']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [-3/2, '- \\frac{3}{2}']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [-3/2, '- \\frac{3}{2}']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [-3/2, '- \\frac{3}{2}']
reward: 0.0
2025-07-13 00:16:37 - WARNING - latex2sympy2_extended.math_normalization - equations is deprecated, as it handled by the parser now
----------------------------------------------------------------------------------------------------

answer_parsed: ['\\Big \\{\\frac{3}{2}\\Big \\}']
gold_parsed: [-3/2, '- \\frac{3}{2}']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [-3/2, '- \\frac{3}{2}']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [-3/2, '- \\frac{3}{2}']
reward: 0.0

accuracy rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
----------------------------------------------------------------------------------------------------

format rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3.157894736842105e-07, 'num_tokens': 128336.0, 'completions/mean_length': 128.0, 'completions/min_length': 128.0, 'completions/max_length': 128.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/accuracy_reward/mean': 0.0, 'rewards/accuracy_reward/std': 0.0, 'rewards/format_reward/mean': 0.0, 'rewards/format_reward/std': 0.0, 'reward': 0.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04}
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [5, '5']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [5, '5']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [5, '5']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [5, '5']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [5, '5']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [5, '5']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [5, '5']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [5, '5']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [5, '5']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [5, '5']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [5, '5']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [5, '5']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [5, '5']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [5, '5']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [5, '5']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [5, '5']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [22, '22']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [22, '22']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [22, '22']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [22, '22']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [22, '22']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [22, '22']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [22, '22']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [22, '22']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [22, '22']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [22, '22']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [22, '22']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [22, '22']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [22, '22']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [22, '22']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [22, '22']
reward: 0.0
----------------------------------------------------------------------------------------------------

answer_parsed: []
gold_parsed: [22, '22']
reward: 0.0

accuracy rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
----------------------------------------------------------------------------------------------------

format rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  File "/data/jcxy/haolu/workspace/frameworks/X-R1/src/x_r1/sgrpo.py", line 294, in <module>
    main(script_args, training_args, model_args )
  File "/data/jcxy/haolu/workspace/frameworks/X-R1/src/x_r1/sgrpo.py", line 258, in main
    train_result = trainer.train(resume_from_checkpoint=checkpoint)
  File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/transformers/trainer.py", line 2245, in train
    return inner_training_loop(
  File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/transformers/trainer.py", line 2560, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/transformers/trainer.py", line 3736, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/trl/extras/profiling.py", line 98, in wrapper
    return func(self, *args, **kwargs)
  File "/data/jcxy/haolu/workspace/frameworks/X-R1/src/x_r1/s_grpo_trainer.py", line 1484, in compute_loss
    return self._compute_loss(model, inputs)
  File "/data/jcxy/haolu/workspace/frameworks/X-R1/src/x_r1/s_grpo_trainer.py", line 1494, in _compute_loss
    per_token_logps = self._get_per_token_logps(model, input_ids, attention_mask, logits_to_keep)
  File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/trl/extras/profiling.py", line 98, in wrapper
    return func(self, *args, **kwargs)
  File "/data/jcxy/haolu/workspace/frameworks/X-R1/src/x_r1/s_grpo_trainer.py", line 949, in _get_per_token_logps
    logits = model(
  File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/accelerate/utils/operations.py", line 818, in forward
    return model_forward(*args, **kwargs)
  File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/accelerate/utils/operations.py", line 806, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
  File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/amp/autocast_mode.py", line 44, in decorate_autocast
    return func(*args, **kwargs)
  File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 856, in forward
    output = self._fsdp_wrapped_module(*args, **kwargs)
  File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/accelerate/utils/operations.py", line 818, in forward
    return model_forward(*args, **kwargs)
  File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/accelerate/utils/operations.py", line 806, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
  File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/amp/autocast_mode.py", line 44, in decorate_autocast
    return func(*args, **kwargs)
  File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/peft/peft_model.py", line 1757, in forward
    return self.base_model(
  File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/peft/tuners/tuners_utils.py", line 193, in forward
    return self.model.forward(*args, **kwargs)
  File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/transformers/utils/generic.py", line 965, in wrapper
    output = func(self, *args, **kwargs)
  File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
    outputs: BaseModelOutputWithPast = self.model(
  File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/transformers/utils/generic.py", line 965, in wrapper
    output = func(self, *args, **kwargs)
  File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
    layer_outputs = decoder_layer(
  File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 856, in forward
    output = self._fsdp_wrapped_module(*args, **kwargs)
  File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 262, in forward
    hidden_states, self_attn_weights = self.self_attn(
  File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 164, in forward
    query_states = self.q_proj(hidden_states).view(hidden_shape).transpose(1, 2)
  File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/peft/tuners/lora/bnb.py", line 516, in forward
    output = lora_B(lora_A(dropout(x))) * scaling
  File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 842, in forward
    args, kwargs = _pre_forward(
  File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/distributed/fsdp/_runtime_utils.py", line 382, in _pre_forward
    unshard_fn(state, handle)
  File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/distributed/fsdp/_runtime_utils.py", line 417, in _pre_forward_unshard
    _unshard(state, handle, state._unshard_stream, state._pre_unshard_stream)
  File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/distributed/fsdp/_runtime_utils.py", line 290, in _unshard
    ran_pre_unshard = handle.pre_unshard()
  File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/distributed/fsdp/_flat_param.py", line 1294, in pre_unshard
    self._use_low_precision_shard()
  File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/distributed/fsdp/_flat_param.py", line 1307, in _use_low_precision_shard
    _alloc_storage(
  File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/distributed/utils.py", line 175, in _alloc_storage
    tensor_storage_size = tensor._typed_storage()._size()
  File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/_tensor.py", line 307, in _typed_storage
    def _typed_storage(self):
KeyboardInterrupt
[rank0]: Traceback (most recent call last):
[rank0]:   File "/data/jcxy/haolu/workspace/frameworks/X-R1/src/x_r1/sgrpo.py", line 294, in <module>
[rank0]:     main(script_args, training_args, model_args )
[rank0]:   File "/data/jcxy/haolu/workspace/frameworks/X-R1/src/x_r1/sgrpo.py", line 258, in main
[rank0]:     train_result = trainer.train(resume_from_checkpoint=checkpoint)
[rank0]:   File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/transformers/trainer.py", line 2245, in train
[rank0]:     return inner_training_loop(
[rank0]:   File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/transformers/trainer.py", line 2560, in _inner_training_loop
[rank0]:     tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
[rank0]:   File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/transformers/trainer.py", line 3736, in training_step
[rank0]:     loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
[rank0]:   File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/trl/extras/profiling.py", line 98, in wrapper
[rank0]:     return func(self, *args, **kwargs)
[rank0]:   File "/data/jcxy/haolu/workspace/frameworks/X-R1/src/x_r1/s_grpo_trainer.py", line 1484, in compute_loss
[rank0]:     return self._compute_loss(model, inputs)
[rank0]:   File "/data/jcxy/haolu/workspace/frameworks/X-R1/src/x_r1/s_grpo_trainer.py", line 1494, in _compute_loss
[rank0]:     per_token_logps = self._get_per_token_logps(model, input_ids, attention_mask, logits_to_keep)
[rank0]:   File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/trl/extras/profiling.py", line 98, in wrapper
[rank0]:     return func(self, *args, **kwargs)
[rank0]:   File "/data/jcxy/haolu/workspace/frameworks/X-R1/src/x_r1/s_grpo_trainer.py", line 949, in _get_per_token_logps
[rank0]:     logits = model(
[rank0]:   File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/accelerate/utils/operations.py", line 818, in forward
[rank0]:     return model_forward(*args, **kwargs)
[rank0]:   File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/accelerate/utils/operations.py", line 806, in __call__
[rank0]:     return convert_to_fp32(self.model_forward(*args, **kwargs))
[rank0]:   File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/amp/autocast_mode.py", line 44, in decorate_autocast
[rank0]:     return func(*args, **kwargs)
[rank0]:   File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 856, in forward
[rank0]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank0]:   File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/accelerate/utils/operations.py", line 818, in forward
[rank0]:     return model_forward(*args, **kwargs)
[rank0]:   File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/accelerate/utils/operations.py", line 806, in __call__
[rank0]:     return convert_to_fp32(self.model_forward(*args, **kwargs))
[rank0]:   File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/amp/autocast_mode.py", line 44, in decorate_autocast
[rank0]:     return func(*args, **kwargs)
[rank0]:   File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/peft/peft_model.py", line 1757, in forward
[rank0]:     return self.base_model(
[rank0]:   File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/peft/tuners/tuners_utils.py", line 193, in forward
[rank0]:     return self.model.forward(*args, **kwargs)
[rank0]:   File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank0]:     output = func(self, *args, **kwargs)
[rank0]:   File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank0]:     return func(*args, **kwargs)
[rank0]:   File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
[rank0]:     outputs: BaseModelOutputWithPast = self.model(
[rank0]:   File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank0]:     output = func(self, *args, **kwargs)
[rank0]:   File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
[rank0]:     layer_outputs = decoder_layer(
[rank0]:   File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 856, in forward
[rank0]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank0]:   File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 262, in forward
[rank0]:     hidden_states, self_attn_weights = self.self_attn(
[rank0]:   File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 164, in forward
[rank0]:     query_states = self.q_proj(hidden_states).view(hidden_shape).transpose(1, 2)
[rank0]:   File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/peft/tuners/lora/bnb.py", line 516, in forward
[rank0]:     output = lora_B(lora_A(dropout(x))) * scaling
[rank0]:   File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 842, in forward
[rank0]:     args, kwargs = _pre_forward(
[rank0]:   File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/distributed/fsdp/_runtime_utils.py", line 382, in _pre_forward
[rank0]:     unshard_fn(state, handle)
[rank0]:   File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/distributed/fsdp/_runtime_utils.py", line 417, in _pre_forward_unshard
[rank0]:     _unshard(state, handle, state._unshard_stream, state._pre_unshard_stream)
[rank0]:   File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/distributed/fsdp/_runtime_utils.py", line 290, in _unshard
[rank0]:     ran_pre_unshard = handle.pre_unshard()
[rank0]:   File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/distributed/fsdp/_flat_param.py", line 1294, in pre_unshard
[rank0]:     self._use_low_precision_shard()
[rank0]:   File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/distributed/fsdp/_flat_param.py", line 1307, in _use_low_precision_shard
[rank0]:     _alloc_storage(
[rank0]:   File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/distributed/utils.py", line 175, in _alloc_storage
[rank0]:     tensor_storage_size = tensor._typed_storage()._size()
[rank0]:   File "/data/jcxy/haolu/anaconda3/envs/haolu/lib/python3.10/site-packages/torch/_tensor.py", line 307, in _typed_storage
[rank0]:     def _typed_storage(self):
[rank0]: KeyboardInterrupt
